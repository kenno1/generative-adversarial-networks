{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow.compat.v1 as tf.compat.v1\n",
    "tf.compat.v1.disable_v2_behavior() \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a37a59f11b0d>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs(real_dim, z_dim):\n",
    "    inputs_real = tf.compat.v1.placeholder(tf.float32, (None, real_dim), name='input_real')\n",
    "    inputs_z = tf.compat.v1.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    \n",
    "    return inputs_real, inputs_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_dim, n_units=128, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        h1 = tf.layers.dense(z, n_units, activation=None)\n",
    "        h1 = tf.maximum(alpha * h1, h1) #Leaky ReLU\n",
    "        \n",
    "        logits = tf.layers.dense(h1, out_dim, activation=None)\n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, n_units=128, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        h1 = tf.layers.dense(x, n_units, activation=None)\n",
    "        h1 = tf.maximum(alpha*h1, h1)\n",
    "        \n",
    "        logits = tf.layers.dense(h1, 1, activation=None)\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Param initialize\n",
    "input_size = 784\n",
    "z_size = 100\n",
    "g_hidden_size = 128\n",
    "d_hidden_size = 128\n",
    "alpha = 0.01\n",
    "smooth = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-f8c48e625d86>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "input_real, input_z = model_inputs(input_size, z_size)\n",
    "\n",
    "g_model = generator(input_z, input_size, n_units=g_hidden_size, alpha=alpha)\n",
    "\n",
    "d_model_real, d_logits_real = discriminator(input_real, n_units=d_hidden_size, alpha=alpha)\n",
    "d_model_fake, d_logits_fake = discriminator(g_model, reuse=True, n_units=d_hidden_size, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kanbekenta/anaconda3/envs/tf16cpu/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#definition loss \n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                           labels=tf.ones_like(d_logits_real)*(1 - smooth)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                           labels = tf.zeros_like(d_logits_real)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                               labels=tf.ones_like(d_logits_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition utilize\n",
    "learning_rate = 0.002\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "d_train_optimize = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "g_train_optimize = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch = mnist.train.next_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([0, 1, 1, 2, 4, 3, 4, 6, 3, 5, 2, 2, 1, 6, 0, 9, 4, 2, 8, 2, 8, 7,\n",
       "        0, 5, 8, 0, 8, 5, 1, 1, 0, 1, 9, 5, 0, 4, 0, 3, 6, 0, 8, 8, 0, 3,\n",
       "        2, 6, 9, 8, 8, 5, 4, 8, 7, 8, 5, 2, 1, 8, 2, 8, 9, 5, 0, 9, 7, 6,\n",
       "        4, 4, 5, 6, 2, 2, 0, 3, 3, 8, 3, 3, 5, 3, 0, 5, 1, 6, 6, 0, 4, 1,\n",
       "        6, 7, 4, 9, 0, 4, 1, 7, 7, 1, 7, 2], dtype=uint8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.43529415, 0.9333334 ,\n",
       "       0.9960785 , 0.9960785 , 0.5019608 , 0.02352941, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.28627452, 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9960785 , 0.7490196 , 0.2627451 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10588236, 0.6117647 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.9960785 , 0.9921569 ,\n",
       "       0.94117653, 0.3019608 , 0.10980393, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.7137255 , 0.9921569 , 0.9921569 , 0.9921569 , 0.909804  ,\n",
       "       0.9843138 , 0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.91372555, 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04705883, 0.7803922 , 0.9921569 ,\n",
       "       0.9921569 , 0.60784316, 0.16078432, 0.49803925, 0.9960785 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.91372555,\n",
       "       0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04313726,\n",
       "       0.42352945, 0.9921569 , 0.9921569 , 0.6       , 0.03529412,\n",
       "       0.        , 0.        , 0.25882354, 0.8705883 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.43529415, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.14509805, 0.9921569 , 0.9921569 ,\n",
       "       0.7607844 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.4156863 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9294118 , 0.27450982, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
       "       0.69411767, 0.9921569 , 0.9921569 , 0.7058824 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "       0.2627451 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.6117647 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3019608 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.2784314 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568628, 0.69411767,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.77647066, 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.5686275 , 0.9921569 , 0.9921569 , 0.76470596, 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.21176472, 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.09411766, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.57254905, 0.9960785 ,\n",
       "       0.9960785 , 0.30588236, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.10196079, 0.86274517, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.32156864, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5686275 , 0.9921569 , 0.9921569 , 0.7568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215688, 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.09411766, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5686275 ,\n",
       "       0.9921569 , 0.9921569 , 0.78823537, 0.03529412, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.4901961 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.93725497, 0.07843138, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.5686275 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.54901963, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09803922, 0.8862746 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.29803923, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.45882356, 0.9921569 , 0.9921569 , 0.9921569 , 0.91372555,\n",
       "       0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.13725491, 0.57254905, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.91372555, 0.10588236, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.07058824, 0.8862746 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.91372555, 0.3529412 ,\n",
       "       0.28627452, 0.28627452, 0.5372549 , 0.8941177 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.52156866, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23529413, 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.7607844 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02352941, 0.45882356, 0.8862746 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.9921569 , 0.9960785 , 0.9921569 ,\n",
       "       0.9921569 , 0.9921569 , 0.72156864, 0.21176472, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.40784317, 0.8941177 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9921569 , 0.9960785 , 0.9921569 , 0.86274517, 0.09411766,\n",
       "       0.02745098, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17254902,\n",
       "       0.5176471 , 0.5176471 , 0.9490197 , 0.9921569 , 0.9960785 ,\n",
       "       0.72156864, 0.21960786, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549/100  D loss: 0.3513  G loss: 4.1933 \n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "samples = []\n",
    "losses = []\n",
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for e in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        batch_images = batch[0].reshape((batch_size, 784))\n",
    "        batch_images = batch_images * 2 - 1\n",
    "        \n",
    "        #Generator\n",
    "        batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "        \n",
    "        _ = sess.run(d_train_optimize, feed_dict = {input_real: batch_images, input_z: batch_z})\n",
    "        _ = sess.run(g_train_optimize, feed_dict = {input_z: batch_z})\n",
    "    \n",
    "    train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n",
    "    train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "\n",
    "    print(\"Epoch {}/{} \".format(e,epochs),\n",
    "    \"D loss: {:.4f} \".format(train_loss_d),\n",
    "    \"G loss: {:.4f} \".format(train_loss_g))\n",
    "    \n",
    "    losses.append((train_loss_d, train_loss_g))\n",
    "    \n",
    "    sample_z = np.random.uniform(-1, 1, size=(18,z_size))\n",
    "    gen_samples = sess.run(generator(input_z, input_size, n_units=g_hidden_size,\n",
    "                                     reuse=True, alpha=alpha),\n",
    "                          feed_dict={input_z: sample_z})\n",
    "    \n",
    "    samples.append(gen_samples)\n",
    "    saver.save(sess, './checkpoints/generator.ckpt')\n",
    "    \n",
    "with open('training_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x6443a7050>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAUgElEQVR4nO3df7BfdZ3f8efLJBIcUH7kApELJFTHGWM3Ea5Rxo6lWCtYFpiVnWVpEewyKVtwtbBT8ceA0O2MuHWXcbHQVNzFXddgYWWihba4oOJMxb2hAQxIjRGGG8FcgvKjEJaEd/+4J/Z6/d7c7733e+/NPff5mDmT8+NzPuf9yWVeOZwf96SqkCTNf6+a6wIkSb1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6FowktyR5Py5rkOaKfE5dO3Pkjw/avE1wEvAnmb5X1fVl2epjkeBC6vqm7NxPGkqFs91AdK+VNVBe+f3FapJFlfV7tmsTdrfeMlF81KSk5MMJflokieBP09yaJJvJBlO8vNmvn/UPt9KcmEzf0GS7yb5j03bnyQ5bQp1HJDk2iQ/baZrkxzQbFvW1PCLJE8nuSfJq5ptH02yPclzSR5J8u4e/dVoATPQNZ8dBRwGHAesY+S/5z9vlo8FXgSu28f+bwceAZYBnwFuTJJJ1vAJ4B3AGmA1sBb4ZLPtMmAI6AOOBD4OVJI3AZcAb6uqg4H3Ao9O8rjSrzHQNZ+9AlxZVS9V1YtVtbOqbq2qF6rqOeA/AP94H/s/VlX/par2ADcByxkJ3sn4F8DVVbWjqoaBq4Dzmm0vN30eV1UvV9U9NXLTag9wAPDmJEuq6tGq+vEkjyv9GgNd89lwVe3au5DkNUn+c5LHkjwLfAc4JMmicfZ/cu9MVb3QzB40TtvxvB54bNTyY806gD8GtgL/M8m2JJc3x9oKfAT4FLAjyYYkr0eaJgNd89nYR7QuA94EvL2qXgu8q1k/2csok/FTRi7x7HVss46qeq6qLquq44EzgEv3Xiuvqr+uqn/U7FvANTNYoxYIA11tcjAj181/keQw4Moe978kydJR02LgK8Ank/QlWQZcAfwVQJLTk7yhuS7/DCOXWl5J8qYkpzQ3T3c1Nb/S41q1ABnoapNrgQOBp4DvAf+9x/3fzkj47p0+BfwRMAg8ADwI3NesA3gj8E3geeB/Af+pqu5m5Pr5p5s6nwSOAD7W41q1APlikSS1hGfoktQSBroktYSBLkktYaBLUkvM2S/nWrZsWa1YsWKuDi9J89KmTZueqqq+TtvmLNBXrFjB4ODgXB1ekualJI+Nt81LLpLUEga6JLWEgS5JLeEXiyQtGC+//DJDQ0Ps2rVr4sZzbOnSpfT397NkyZKu9zHQJS0YQ0NDHHzwwaxYsYLJf8tk9lQVO3fuZGhoiJUrV3a9n5dcJC0Yu3bt4vDDD9+vwxwgCYcffvik/0/CQJe0oOzvYb7XVOo00CWpJQx0SZpFixYtYs2aNaxatYrVq1fz2c9+llde6c33TbwpKkmz6MADD2Tz5s0A7Nixg3PPPZdnn32Wq666atp9e4YuSXPkiCOOYP369Vx33XX04mNDnqFLWpCu+voWHvrpsz3t882vfy1X/uaqSe1z/PHHs2fPHnbs2MGRRx45reN7hi5JLeEZuqQFabJn0jNl27ZtLFq0iCOOOGLafXmGLklzZHh4mIsuuohLLrmkJ8/Hd32GnmQRMAhsr6rTx2w7APgScCKwE/idqnp02tVJUsu8+OKLrFmzhpdffpnFixdz3nnncemll/ak78lccvkw8DDw2g7bfg/4eVW9Ick5wDXA7/SgPklqlT179sxY311dcknSD/xz4AvjNDkTuKmZvwV4d+bL+7WS1BLdXkO/Fvh3wHivMx0NPA5QVbuBZ4DDxzZKsi7JYJLB4eHhKZQrSRrPhIGe5HRgR1Vtmu7Bqmp9VQ1U1UBfX8dvnEqSpqibM/R3AmckeRTYAJyS5K/GtNkOHAOQZDHwOkZujkqSZsmEgV5VH6uq/qpaAZwD3FVV/3JMs43A+c382U2b6b/HKknq2pRfLEpyNTBYVRuBG4G/TLIVeJqR4JckzaJJvVhUVd/a+wx6VV3RhDlVtauqfruq3lBVa6tq20wUK0lt8LOf/Yxzzz2X448/nhNPPJGTTjqJr33ta9Pu1zdFJWkWVRVnnXUW73rXu9i2bRubNm1iw4YNDA0NTbtvA12SZtFdd93Fq1/9ai666KJfrjvuuOP40Ic+NO2+/eVckhamOy6HJx/sbZ9H/UM47dP7bLJlyxZOOOGE3h634Rm6JM2hiy++mNWrV/O2t71t2n15hi5pYZrgTHqmrFq1iltvvfWXy5///Od56qmnGBgYmHbfnqFL0iw65ZRT2LVrF9dff/0v173wwgs96dtAl6RZlITbbruNb3/726xcuZK1a9dy/vnnc80110y7by+5SNIsW758ORs2bOh5v56hS1JLGOiS1BIGuqQFZb783sCp1GmgS1owli5dys6dO/f7UK8qdu7cydKlSye1nzdFJS0Y/f39DA0NMR++mLZ06VL6+/sntY+BLmnBWLJkCStXrpzrMmaMl1wkqSUMdElqCQNdklpiwkBPsjTJ95Pcn2RLkqs6tLkgyXCSzc104cyUK0kaTzc3RV8CTqmq55MsAb6b5I6q+t6YdjdX1SW9L1GS1I0JA71GHth8vllc0kz790OckrQAdXUNPcmiJJuBHcCdVXVvh2bvT/JAkluSHDNOP+uSDCYZnA/PgUrSfNJVoFfVnqpaA/QDa5O8ZUyTrwMrquo3gDuBm8bpZ31VDVTVQF9f33TqliSNMamnXKrqF8DdwKlj1u+sqpeaxS8AJ/amPElSt7p5yqUvySHN/IHAe4AfjmmzfNTiGcDDvSxSkjSxbp5yWQ7clGQRI/8AfLWqvpHkamCwqjYCf5DkDGA38DRwwUwVLEnqLHP1W8cGBgZqcHBwTo4tSfNVkk1V1fGL0r4pKkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLVEN5+gW5rk+0nuT7IlyVUd2hyQ5OYkW5Pcm2TFTBQrSRpfN2foLwGnVNVqYA1wapJ3jGnze8DPq+oNwJ8C1/S2TEnSRCYM9BrxfLO4pJnGfrfuTOCmZv4W4N1J0rMqJUkT6uoaepJFSTYDO4A7q+reMU2OBh4HqKrdwDPA4b0sVJK0b10FelXtqao1QD+wNslbpnKwJOuSDCYZHB4enkoXkqRxTOopl6r6BXA3cOqYTduBYwCSLAZeB+zssP/6qhqoqoG+vr6pVSxJ6qibp1z6khzSzB8IvAf44ZhmG4Hzm/mzgbuqaux1dknSDFrcRZvlwE1JFjHyD8BXq+obSa4GBqtqI3Aj8JdJtgJPA+fMWMWSpI4mDPSqegB4a4f1V4ya3wX8dm9LkyRNhm+KSlJLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSS3TzTdFjktyd5KEkW5J8uEObk5M8k2RzM13RqS9J0szp5puiu4HLquq+JAcDm5LcWVUPjWl3T1Wd3vsSJUndmPAMvaqeqKr7mvnngIeBo2e6MEnS5EzqGnqSFYx8MPreDptPSnJ/kjuSrBpn/3VJBpMMDg8PT7pYSdL4ug70JAcBtwIfqapnx2y+DziuqlYDfwbc1qmPqlpfVQNVNdDX1zfVmiVJHXQV6EmWMBLmX66qvxm7vaqerarnm/nbgSVJlvW0UknSPnXzlEuAG4GHq+pPxmlzVNOOJGubfnf2slBJ0r5185TLO4HzgAeTbG7WfRw4FqCqbgDOBn4/yW7gReCcqqoZqFeSNI4JA72qvgtkgjbXAdf1qihJ0uT5pqgktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLVEN98UPSbJ3UkeSrIlyYc7tEmSzyXZmuSBJCfMTLmSpPF0803R3cBlVXVfkoOBTUnurKqHRrU5DXhjM70duL75U5I0SyY8Q6+qJ6rqvmb+OeBh4Ogxzc4EvlQjvgcckmR5z6uVJI1rUtfQk6wA3grcO2bT0cDjo5aH+PXQJ8m6JINJBoeHhydXqSRpn7oO9CQHAbcCH6mqZ6dysKpaX1UDVTXQ19c3lS4kSePoKtCTLGEkzL9cVX/Tocl24JhRy/3NOknSLOnmKZcANwIPV9WfjNNsI/CB5mmXdwDPVNUTPaxTkjSBbp5yeSdwHvBgks3Nuo8DxwJU1Q3A7cD7gK3AC8AHe1+qJGlfJgz0qvoukAnaFHBxr4qSJE2eb4pKUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktYaBLUksY6JLUEga6JLWEgS5JLWGgS1JLdPNN0S8m2ZHkB+NsPznJM0k2N9MVvS9TkjSRbr4p+hfAdcCX9tHmnqo6vScVSZKmZMIz9Kr6DvD0LNQiSZqGXl1DPynJ/UnuSLJqvEZJ1iUZTDI4PDzco0NLkqA3gX4fcFxVrQb+DLhtvIZVtb6qBqpqoK+vrweHliTtNe1Ar6pnq+r5Zv52YEmSZdOuTJI0KdMO9CRHJUkzv7bpc+d0+5UkTc6ET7kk+QpwMrAsyRBwJbAEoKpuAM4Gfj/JbuBF4JyqqhmrWJLU0YSBXlW/O8H26xh5rFGSNId8U1SSWsJAl6SWMNAlqSUMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqiQkDPckXk+xI8oNxtifJ55JsTfJAkhN6X6YkaSLdnKH/BXDqPrafBryxmdYB10+/LEnSZE0Y6FX1HeDpfTQ5E/hSjfgecEiS5b0qUJLUnV5cQz8aeHzU8lCzTpI0i2b1pmiSdUkGkwwODw/P5qElqfV6EejbgWNGLfc3635NVa2vqoGqGujr6+vBoSVJe/Ui0DcCH2iednkH8ExVPdGDfiVJk7B4ogZJvgKcDCxLMgRcCSwBqKobgNuB9wFbgReAD85UsZKk8U0Y6FX1uxNsL+DinlUkSZoS3xSVpJYw0CWpJQx0SWoJA12SWsJAl6SWMNAlqSUMdElqCQNdklrCQJekljDQJaklDHRJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SW6CrQk5ya5JEkW5Nc3mH7BUmGk2xupgt7X6okaV+6+aboIuDzwHuAIeDvkmysqofGNL25qi6ZgRolSV3o5gx9LbC1qrZV1d8DG4AzZ7YsSdJkdRPoRwOPj1oeataN9f4kDyS5JckxnTpKsi7JYJLB4eHhKZQrSRpPr26Kfh1YUVW/AdwJ3NSpUVWtr6qBqhro6+vr0aElSdBdoG8HRp9x9zfrfqmqdlbVS83iF4ATe1OeJKlb3QT63wFvTLIyyauBc4CNoxskWT5q8Qzg4d6VKEnqxoRPuVTV7iSXAP8DWAR8saq2JLkaGKyqjcAfJDkD2A08DVwwgzVLkjpIVc3JgQcGBmpwcHBOji1J81WSTVU10Gmbb4pKUksY6JLUEga6JLWEgS5JLWGgS1JLGOiS1BIGuiS1hIEuSS1hoEtSSxjoktQSBroktYSBLkktMWe/nCvJMPDYnBx8epYBT811EbPMMbffQhsvzN8xH1dVHb8QNGeBPl8lGRzvN521lWNuv4U2XmjnmL3kIkktYaBLUksY6JO3fq4LmAOOuf0W2nihhWP2GroktYRn6JLUEga6JLWEgd5BksOS3JnkR82fh47T7vymzY+SnN9h+8YkP5j5iqdvOmNO8pok/y3JD5NsSfLp2a2+e0lOTfJIkq1JLu+w/YAkNzfb702yYtS2jzXrH0ny3tmsezqmOuYk70myKcmDzZ+nzHbtUzWdn3Oz/dgkzyf5w9mquSeqymnMBHwGuLyZvxy4pkObw4BtzZ+HNvOHjtr+W8BfAz+Y6/HM9JiB1wD/pGnzauAe4LS5HlOH+hcBPwaOb+q8H3jzmDb/BrihmT8HuLmZf3PT/gBgZdPPorke0wyP+a3A65v5twDb53o8Mz3mUdtvAf4r8IdzPZ7JTJ6hd3YmcFMzfxNwVoc27wXurKqnq+rnwJ3AqQBJDgIuBf5oFmrtlSmPuapeqKq7Aarq74H7gP5ZqHmy1gJbq2pbU+cGRsY92ui/h1uAdydJs35DVb1UVT8Btjb97e+mPOaq+t9V9dNm/RbgwCQHzErV0zOdnzNJzgJ+wsiY5xUDvbMjq+qJZv5J4MgObY4GHh+1PNSsA/j3wGeBF2aswt6b7pgBSHII8JvA385EkdM0Yf2j21TVbuAZ4PAu990fTWfMo70fuK+qXpqhOntpymNuTsY+Clw1C3X23OK5LmCuJPkmcFSHTZ8YvVBVlaTrZzuTrAH+QVX927HX5ebaTI15VP+Lga8An6uqbVOrUvubJKuAa4B/Nte1zIJPAX9aVc83J+zzyoIN9Kr6p+NtS/KzJMur6okky4EdHZptB04etdwPfAs4CRhI8igjf79HJPlWVZ3MHJvBMe+1HvhRVV3bg3JnwnbgmFHL/c26Tm2Gmn+gXgfs7HLf/dF0xkySfuBrwAeq6sczX25PTGfMbwfOTvIZ4BDglSS7quq6mS+7B+b6Iv7+OAF/zK/eIPxMhzaHMXKd7dBm+glw2Jg2K5g/N0WnNWZG7hfcCrxqrseyjzEuZuRG7kr+/82yVWPaXMyv3iz7ajO/il+9KbqN+XFTdDpjPqRp/1tzPY7ZGvOYNp9int0UnfMC9seJkeuHfwv8CPjmqNAaAL4wqt2/YuTm2Fbggx36mU+BPuUxM3IGVMDDwOZmunCuxzTOON8H/B9GnoL4RLPuauCMZn4pI083bAW+Dxw/at9PNPs9wn74FE+vxwx8Evi/o36mm4Ej5no8M/1zHtXHvAt0X/2XpJbwKRdJagkDXZJawkCXpJYw0CWpJQx0SWoJA12SWsJAl6SW+H+NQ7EdtXzkngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='D')\n",
    "plt.plot(losses.T[1], label='G')\n",
    "plt.title('Train Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
